[net]
# Training
batch=512
subdivisions=16

label_smooth_eps=0.1

# Testing
# batch=1
# subdivisions=1

height=256
width=256
channels=3
min_crop=128
max_crop=448

mosaic=1
cutmix=1

burn_in=1000
learning_rate=0.1
policy=poly
power=4
max_batches=300000
momentum=0.9
decay=0.0005

angle=7
hue=.1
saturation=.75
exposure=.75
aspect=.75



[convolutional]
batch_normalize=2
filters=64
size=7
stride=2
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -2

[convolutional]
batch_normalize=2
filters=64
size=1
stride=1
pad=1
activation=leaky

# 1-1

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=128
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

# 1-2

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=128
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

# 1-3

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=128
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

# 1-T

[convolutional]
batch_normalize=2
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-16

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=3
groups=32
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=linear

# 2-1

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

# 2-2

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

# 2-3

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=linear

[shortcut]
from=-4
activation=leaky

# 2-T

[convolutional]
batch_normalize=2
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-16

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=3
groups=32
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=linear

# 3-1

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=linear

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

[shortcut]
from=-5
activation=leaky

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

# 3-2

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=linear

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

[shortcut]
from=-6
activation=leaky

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

# 3-3

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=linear

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

[shortcut]
from=-6
activation=leaky

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

# 3-4

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=linear

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

[shortcut]
from=-6
activation=leaky

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

# 3-5

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=linear

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

[shortcut]
from=-6
activation=leaky

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.025

# 3-T

[convolutional]
batch_normalize=2
filters=512
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-34

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=1024
size=3
groups=32
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -2

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=leaky

# 4-1

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=1024
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=linear

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.1

[shortcut]
from=-5
activation=leaky

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.1

# 4-2

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=1024
size=3
groups=32
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=linear

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.1

[shortcut]
from=-6
activation=leaky

[dropout]
dropblock=1
dropblock_size_abs=7
probability=0.1

# 4-T

[convolutional]
batch_normalize=2
filters=1024
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-16

[convolutional]
batch_normalize=2
filters=2048
size=1
stride=1
pad=1
activation=leaky

[avgpool]

[convolutional]
filters=1000
size=1
stride=1
pad=1
activation=linear

[softmax]
groups=1
